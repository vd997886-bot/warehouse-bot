import os
import re
import pandas as pd

from telegram import Update
from telegram.ext import ApplicationBuilder, MessageHandler, ContextTypes, filters

# ========== SETTINGS ==========
TOKEN = os.getenv("TOKEN")
EXCEL_FILE = "warehouse.xlsx"

REQUIRED_COLUMNS = {
    "PartNumber",
    "Quantity",
    "Shelf",
    "Location",
    "Passport",
    "Category",
    "SerialNumber",
    "Check",
}
# ==============================


def normalize_text(v) -> str:
    if pd.isna(v):
        return ""
    return str(v).strip()


def to_yes(v) -> bool:
    v = normalize_text(v).lower()
    return v in {"yes", "y", "true", "1", "Ğ´Ğ°", "ok", "checked"}


def norm_key(s: str) -> str:
    """
    ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ "Ğ¿Ğ¾Ñ…Ğ¾Ğ¶ĞµĞ³Ğ¾" Ğ¿Ğ¾Ğ¸ÑĞºĞ°:
    - upper
    - ÑƒĞ±Ñ€Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹, Ğ´ĞµÑ„Ğ¸ÑÑ‹, ÑĞ»ÑÑˆĞ¸, Ñ‚Ğ¾Ñ‡ĞºĞ¸, Ğ·Ğ°Ğ¿ÑÑ‚Ñ‹Ğµ Ğ¸ Ñ‚.Ğ¿.
    """
    s = normalize_text(s).upper()
    s = re.sub(r"[\s\-\_/\\\.,;:]+", "", s)
    return s


def make_fuzzy_regex(query: str) -> re.Pattern:
    """
    Ğ”ĞµĞ»Ğ°ĞµÑ‚ regex, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¸ÑĞºĞ°Ñ‚ÑŒ Ñ Ğ»ÑĞ±Ñ‹Ğ¼Ğ¸ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑĞ¼Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°Ğ¼Ğ¸/Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ğ¼Ğ¸.
    ĞŸÑ€Ğ¸Ğ¼ĞµÑ€: "PH6002CEP" Ğ½Ğ°Ğ¹Ğ´Ñ‘Ñ‚ "PH-600 2 Cep"
    """
    q = norm_key(query)
    if not q:
        return re.compile(r"$^")  # Ğ½Ğ¸ĞºĞ¾Ğ³Ğ´Ğ° Ğ½Ğµ Ğ¼Ğ°Ñ‚Ñ‡Ğ¸Ñ‚ÑÑ

    # Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°Ğ¼Ğ¸ Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞ¸Ğ¼ Ğ»ÑĞ±Ñ‹Ğµ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»Ğ¸/Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹
    # + Ğ´ĞµĞ»Ğ°ĞµĞ¼ â€œĞ¼ÑĞ³ĞºĞ¾â€, Ğ½Ğ¾ Ğ±ĞµĞ· Ğ´Ğ¸ĞºĞ¾Ğ³Ğ¾ Ñ‚Ğ¾Ñ€Ğ¼Ğ¾Ğ·Ğ°
    parts = list(q)
    pattern = r".*".join(map(re.escape, parts))
    return re.compile(pattern, re.IGNORECASE)


def safe_int(v) -> int:
    try:
        if pd.isna(v):
            return 0
        return int(float(v))
    except Exception:
        return 0


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query_raw = (update.message.text or "").strip()
    if not query_raw:
        return

    try:
        df = pd.read_excel(EXCEL_FILE)
        df.columns = [str(c).strip() for c in df.columns]

        if not REQUIRED_COLUMNS.issubset(set(df.columns)):
            missing = sorted(list(REQUIRED_COLUMNS - set(df.columns)))
            await update.message.reply_text(
                "âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ² Excel Ğ½Ğµ Ñ…Ğ²Ğ°Ñ‚Ğ°ĞµÑ‚ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº:\n" + ", ".join(missing)
            )
            return

        # ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼ PartNumber Ğº ÑÑ‚Ñ€Ğ¾ĞºĞµ
        df["PartNumber"] = df["PartNumber"].astype(str)

        # 1) ĞĞ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ contains (Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹)
        contains_matches = df[df["PartNumber"].str.contains(query_raw, case=False, na=False)]

        # 2) "ĞŸĞ¾Ñ…Ğ¾Ğ¶Ğ¸Ğ¹" Ğ¿Ğ¾Ğ¸ÑĞº (Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ)
        qk = norm_key(query_raw)
        df["_pn_norm"] = df["PartNumber"].map(norm_key)
        fuzzy_matches = df[df["_pn_norm"].str.contains(qk, na=False)] if qk else df.iloc[0:0]

        # 3) Ğ•Ñ‰Ñ‘ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¼ÑĞ³ĞºĞ¾: regex Ğ¿Ğ¾ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°Ğ¼ (ĞµÑĞ»Ğ¸ Ğ²Ğ¾Ğ¾Ğ±Ñ‰Ğµ Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ½Ğ°ÑˆĞ»Ğ¸)
        if contains_matches.empty and fuzzy_matches.empty:
            rgx = make_fuzzy_regex(query_raw)
            regex_matches = df[df["PartNumber"].str.contains(rgx, na=False)]
        else:
            regex_matches = df.iloc[0:0]

        # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ÑÑ‘ Ğ¸ ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹
        matches = pd.concat([contains_matches, fuzzy_matches, regex_matches]).drop_duplicates()

        if matches.empty:
            await update.message.reply_text("â“ ĞĞ¸Ñ‡ĞµĞ³Ğ¾ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶ĞµĞ³Ğ¾ Ğ½Ğµ Ğ½Ğ°ÑˆĞ»Ğ° Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğµ")
            return

        # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ¼ Ğ¾Ñ‚Ğ²ĞµÑ‚, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ñ‚ĞµĞ»ĞµĞ³Ğ° Ğ½Ğµ Ğ²Ğ·Ğ¾Ñ€Ğ²Ğ°Ğ»Ğ°ÑÑŒ, ĞµÑĞ»Ğ¸ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¼Ğ½Ğ¾Ğ³Ğ¾
        matches = matches.head(10)

        responses = []
        for _, row in matches.iterrows():
            part = normalize_text(row["PartNumber"])
            qty = safe_int(row["Quantity"])
            shelf = normalize_text(row["Shelf"])
            location = normalize_text(row["Location"])

            passport = "ĞµÑÑ‚ÑŒ" if to_yes(row["Passport"]) else "Ğ½ĞµÑ‚"

            cat_raw = normalize_text(row["Category"]).lower()
            category = "Ğ½Ğ¾Ğ²Ğ°Ñ" if cat_raw == "new" else "ÑÑ‚Ğ°Ñ€Ğ°Ñ"

            serial = normalize_text(row["SerialNumber"]) or "â€”"
            checked = "Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ°" if to_yes(row["Check"]) else "Ğ½Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ°"

            if qty > 0:
                responses.append(
                    f"âœ… {part} ĞµÑÑ‚ÑŒ Ğ² Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğ¸\n"
                    f"ğŸ“¦ ĞŸĞ¾Ğ»ĞºĞ°: {shelf}, ÑÑ‡ĞµĞ¹ĞºĞ°: {location}\n"
                    f"ğŸ”¢ ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾: {qty}\n"
                    f"ğŸ“„ ĞŸĞ°ÑĞ¿Ğ¾Ñ€Ñ‚: {passport}\n"
                    f"ğŸ†• ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ: {category}\n"
                    f"ğŸ”‘ Ğ¡ĞµÑ€Ğ¸Ğ¹Ğ½Ñ‹Ğ¹ Ğ½Ğ¾Ğ¼ĞµÑ€: {serial}\n"
                    f"âœ”ï¸ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ°: {checked}"
                )
            else:
                responses.append(
                    f"âŒ {part} Ğ½ĞµÑ‚ Ğ² Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğ¸\n"
                    f"ğŸ“„ ĞŸĞ°ÑĞ¿Ğ¾Ñ€Ñ‚: {passport}\n"
                    f"ğŸ†• ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ: {category}\n"
                    f"ğŸ”‘ Ğ¡ĞµÑ€Ğ¸Ğ¹Ğ½Ñ‹Ğ¹ Ğ½Ğ¾Ğ¼ĞµÑ€: {serial}\n"
                    f"âœ”ï¸ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ°: {checked}"
                )

        await update.message.reply_text("\n\n".join(responses))

    except Exception as e:
        await update.message.reply_text(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")


def main():
    if not TOKEN:
        raise ValueError("TOKEN is not set. Add TOKEN in Railway Variables.")
    app = ApplicationBuilder().token(TOKEN).build()
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    print("ğŸ¤– Avacs Stock Bot started")
    app.run_polling(drop_pending_updates=True)


if __name__ == "__main__":
    main()
