import os
import re
import difflib
import pandas as pd

from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    MessageHandler,
    CommandHandler,
    ContextTypes,
    filters,
)

# ========== SETTINGS ==========
TOKEN = os.getenv("TOKEN")  # set in Railway Variables
FILE_PATH = "warehouse.xlsx"

REQUIRED_COLUMNS = {
    "PartNumber",
    "Quantity",
    "Shelf",
    "Location",
    "Passport",
    "Category",
    "SerialNumber",
    "Check",
}
# ==============================


def normalize_text(v) -> str:
    if pd.isna(v):
        return ""
    return str(v).strip()


def to_yes(v) -> bool:
    s = normalize_text(v).lower()
    return s in {"yes", "y", "true", "1", "–¥–∞", "ok", "checked", "–µ—Å—Ç—å"}


def normalize_part_for_search(s: str) -> str:
    """
    –î–µ–ª–∞–µ—Ç –ø–æ–∏—Å–∫ "–ø–æ—Ö–æ–∂–µ–≥–æ" –ª—É—á—à–µ:
    - –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä
    - —É–±–∏—Ä–∞–µ—Ç –ø—Ä–æ–±–µ–ª—ã, –¥–µ—Ñ–∏—Å—ã, —Å–ª–µ—à–∏, —Ç–æ—á–∫–∏
    """
    s = normalize_text(s).lower()
    s = re.sub(r"[ \t\r\n\-\._/\\]+", "", s)
    return s


def safe_int(v) -> int:
    try:
        if pd.isna(v):
            return 0
        return int(float(v))
    except Exception:
        return 0


def fmt_row(row) -> str:
    part = normalize_text(row["PartNumber"])
    qty = safe_int(row["Quantity"])
    shelf = normalize_text(row["Shelf"])
    location = normalize_text(row["Location"])

    passport = "–µ—Å—Ç—å" if to_yes(row["Passport"]) else "–Ω–µ—Ç"

    cat_raw = normalize_text(row["Category"]).lower()
    if cat_raw in {"new", "–Ω–æ–≤–∞", "–Ω–æ–≤–∞—è"}:
        category = "–Ω–æ–≤–∞—è"
    elif cat_raw in {"old", "—Å—Ç–∞—Ä–∞", "—Å—Ç–∞—Ä–∞—è"}:
        category = "—Å—Ç–∞—Ä–∞—è"
    else:
        category = normalize_text(row["Category"]) or "‚Äî"

    serial = normalize_text(row["SerialNumber"]) or "‚Äî"
    checked = "–ø—Ä–æ–≤–µ—Ä–µ–Ω–∞" if to_yes(row["Check"]) else "–Ω–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞"

    if qty > 0:
        return (
            f"‚úÖ {part} –µ—Å—Ç—å –≤ –Ω–∞–ª–∏—á–∏–∏\n"
            f"üì¶ –ü–æ–ª–∫–∞: {shelf}, —è—á–µ–π–∫–∞: {location}\n"
            f"üî¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {qty}\n"
            f"üìÑ –ü–∞—Å–ø–æ—Ä—Ç: {passport}\n"
            f"üÜï –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}\n"
            f"üîë –°–µ—Ä–∏–π–Ω—ã–π –Ω–æ–º–µ—Ä: {serial}\n"
            f"‚úîÔ∏è –ü—Ä–æ–≤–µ—Ä–∫–∞: {checked}"
        )
    else:
        return (
            f"‚ùå {part} –Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏\n"
            f"üìÑ –ü–∞—Å–ø–æ—Ä—Ç: {passport}\n"
            f"üÜï –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}\n"
            f"üîë –°–µ—Ä–∏–π–Ω—ã–π –Ω–æ–º–µ—Ä: {serial}\n"
            f"‚úîÔ∏è –ü—Ä–æ–≤–µ—Ä–∫–∞: {checked}"
        )


def load_df():
    if not os.path.exists(FILE_PATH):
        raise FileNotFoundError(
            f"–§–∞–π–ª {FILE_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–∏—à–ª–∏ –µ–≥–æ –±–æ—Ç—É –≤ Telegram –∫–∞–∫ .xlsx"
        )

    df = pd.read_excel(FILE_PATH)
    df.columns = [str(c).strip() for c in df.columns]

    if not REQUIRED_COLUMNS.issubset(set(df.columns)):
        missing = sorted(list(REQUIRED_COLUMNS - set(df.columns)))
        raise ValueError("–í Excel –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –∫–æ–ª–æ–Ω–æ–∫: " + ", ".join(missing))

    # –≥–æ—Ç–æ–≤–∏–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –ø–æ–ª—è
    df["PartNumber"] = df["PartNumber"].astype(str)
    df["_pn_norm"] = df["PartNumber"].apply(normalize_part_for_search)
    return df


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç üëã\n"
        "–ù–∞–ø–∏—à–∏ PartNumber (–∏–ª–∏ —á–∞—Å—Ç—å –Ω–æ–º–µ—Ä–∞) ‚Äî —è –Ω–∞–π–¥—É.\n"
        "–ß—Ç–æ–±—ã –æ–±–Ω–æ–≤–∏—Ç—å –±–∞–∑—É ‚Äî –ø—Ä–∏—à–ª–∏ Excel —Ñ–∞–π–ª–æ–º (.xlsx) —Å—é–¥–∞ –≤ —á–∞—Ç."
    )


async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/start ‚Äî —Å—Ç–∞—Ä—Ç\n"
        "/help ‚Äî –ø–æ–º–æ—â—å\n\n"
        "1) –ü–æ–∏—Å–∫: –ø—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å PartNumber –∏–ª–∏ —á–∞—Å—Ç—å\n"
        "2) –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ: –æ—Ç–ø—Ä–∞–≤—å .xlsx —Ñ–∞–π–ª–æ–º ‚Äî —è –∑–∞–º–µ–Ω—é warehouse.xlsx"
    )


async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    doc = update.message.document
    if not doc:
        return

    name = doc.file_name or ""
    if not name.lower().endswith(".xlsx"):
        await update.message.reply_text("‚ùå –ü—Ä–∏—à–ª–∏ –∏–º–µ–Ω–Ω–æ Excel —Ñ–∞–π–ª (.xlsx)")
        return

    # —Å–∫–∞—á–∏–≤–∞–µ–º –∏ –∑–∞–º–µ–Ω—è–µ–º warehouse.xlsx
    tg_file = await context.bot.get_file(doc.file_id)
    await tg_file.download_to_drive(FILE_PATH)

    # –±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Ñ–∞–π–ª –Ω–æ—Ä–º —á–∏—Ç–∞–µ—Ç—Å—è –∏ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å—Ç—å
    try:
        _ = load_df()
    except Exception as e:
        await update.message.reply_text(f"‚ö†Ô∏è –§–∞–π–ª —Å–∫–∞—á–∞–ª—Å—è, –Ω–æ –µ—Å—Ç—å –æ—à–∏–±–∫–∞:\n{e}")
        return

    await update.message.reply_text("‚úÖ –¢–∞–±–ª–∏—Ü–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞! –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–∫–∞—Ç—å.")


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()
    if not text:
        return

    query_raw = text
    query_norm = normalize_part_for_search(query_raw)

    try:
        df = load_df()
    except Exception as e:
        await update.message.reply_text(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
        return

    # 1) –¢–æ—á–Ω–æ–µ/—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –Ω–æ–º–µ—Ä—É)
    exact = df[df["_pn_norm"].str.contains(query_norm, na=False)]

    # –µ—Å–ª–∏ –µ—Å—Ç—å ‚Äî –æ—Ç–¥–∞–µ–º
    if not exact.empty:
        responses = [fmt_row(row) for _, row in exact.iterrows()]
        await update.message.reply_text("\n\n".join(responses[:20]))
        if len(responses) > 20:
            await update.message.reply_text("‚ÑπÔ∏è –ù–∞—à–ª–∞ –º–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π, –ø–æ–∫–∞–∑–∞–ª–∞ –ø–µ—Ä–≤—ã–µ 20.")
        return

    # 2) Fuzzy –ø–æ–∏—Å–∫ (–ø–æ—Ö–æ–∂–µ–µ)
    pn_list = df["_pn_norm"].tolist()
    close = difflib.get_close_matches(query_norm, pn_list, n=8, cutoff=0.6)

    if close:
        fuzzy = df[df["_pn_norm"].isin(close)]
        responses = [fmt_row(row) for _, row in fuzzy.iterrows()]
        await update.message.reply_text(
            "ü§î –¢–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–µ—Ç, –Ω–æ –Ω–∞—à–ª–∞ –ø–æ—Ö–æ–∂–∏–µ:\n\n" + "\n\n".join(responses)
        )
        return

    await update.message.reply_text("‚ùì –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∞ –ø–æ —ç—Ç–æ–º—É –∑–∞–ø—Ä–æ—Å—É")


def main():
    if not TOKEN:
        raise RuntimeError("TOKEN –Ω–µ –∑–∞–¥–∞–Ω. –î–æ–±–∞–≤—å TOKEN –≤ Railway Variables.")

    app = ApplicationBuilder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))

    # –í–ê–ñ–ù–û: —Å–Ω–∞—á–∞–ª–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã, –ø–æ—Ç–æ–º —Ç–µ–∫—Å—Ç
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    print("ü§ñ Warehouse bot started")
    app.run_polling(drop_pending_updates=True)


if __name__ == "__main__":
    main()
